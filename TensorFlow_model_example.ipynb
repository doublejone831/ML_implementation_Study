{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Tensorflow based NeuralNet without any libs\n",
    "This python notebook is for studying how to make NeuralNet model using Tensorflow\n",
    "Keras is just used for load the dataset\n",
    "Reference:\n",
    "1. https://www.kaggle.com/code/enriqueabad/using-tensorflow-from-scratch-without-keras/notebook\n",
    "2. https://www.tensorflow.org/tutorials/quickstart/beginner?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version:  2.10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder, scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "print(\"TensorFlow Version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load MNist Dataset from the keras\n",
    "\"\"\"\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(60000, 28, 28)\n",
      "(60000, 1)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Normalize the input to make it inside of range 0 to 1\"\"\"\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(type(x_train))\n",
    "print(x_train.shape)\n",
    "print(y_train.reshape(-1,1).shape)\n",
    "print(y_test.reshape(-1,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make label as an one hot vector\n",
    "\"\"\"\n",
    "label_encoder = OneHotEncoder(categories=[np.arange(10)])\n",
    "\"\"\"\n",
    "Need to make 1D array to 2D array So use ndarray.reshape()\n",
    "We use -1 to indicate the length of row or column dynamically\n",
    "\"\"\"\n",
    "y_train = label_encoder.fit_transform(y_train.reshape(-1,1))\n",
    "y_test = label_encoder.fit_transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Neural Network without hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make weight tensor\n",
    "We have 784 pixel image so the weight tensor size should be 784 x 10\n",
    "-> 784 pixel and out put is 10\n",
    "tf.Variable => tensor in tensorflow is immutable.\n",
    "So we use variables which is tensor whose value can be changed by running ops on it. \n",
    "\"\"\"\n",
    "# weight_random = tf.Variable(tf.random.uniform([784,10]))\n",
    "weight_random = tf.Variable(tf.zeros([784,10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make the loss function -> mean squared error loss and cross-entropy loss \n",
    "\"\"\"\n",
    "def loss_MSE(target_y, predicted_y):\n",
    "    return tf.reduce_mean(tf.square(target_y-predicted_y))\n",
    "\n",
    "def loss_CrossEntrophy(target_y, predicted_y):\n",
    "    return -tf.reduce_sum(tf.reduce_mean(np.multiply(target_y,tf.math.log(predicted_y+1e-12)),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Define Flatten Layer\"\"\"\n",
    "def flatten(t):\n",
    "    \"\"\"\n",
    "    By using np.reshape, reshape tensor to 1D\n",
    "    \"\"\"\n",
    "    return t.reshape(t.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(flatten(x_train).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make model\n",
    "Make model using tf.Module makes it easier to build own model\n",
    "tf.Module is Base neural network module class\n",
    "Module  is an named container for tf.Variable s, other tf.Module s and functions which apply to user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(tf.Module):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \"\"\"\n",
    "        Weight starts with zeros \n",
    "        But it is better to start with random\n",
    "\n",
    "        \"\"\"\n",
    "        self.w = tf.Variable(tf.zeros([784,10]))\n",
    "        #self.w = tf.Variable(tf.random.uniform[784,10])\n",
    "        self.b = tf.Variable(0.0)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        \"\"\" \n",
    "        With just call the class, we can predict\n",
    "        y_predicted = Model1()(x_data)\n",
    "        \"\"\"\n",
    "        x = flatten(x)\n",
    "        return tf.nn.softmax((x @ self.w + self.b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,x,y,learning_rate):\n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = loss_CrossEntrophy(y,model(x))\n",
    "    \n",
    "    dw, db = t.gradient(current_loss, [model.w, model.b])\n",
    "\n",
    "    model.w.assign_sub(learning_rate*dw)\n",
    "    model.b.assign_sub(learning_rate*db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for i_epochs in tqdm(range(50)):\n",
    "    train(model, x_train, y_train, learning_rate=0.2)\n",
    "    train_loss = loss_CrossEntrophy(y_train, model(x_train))\n",
    "    test_loss = loss_CrossEntrophy(y_test, model(x_test))\n",
    "    print(f\"Training loss in epoch {i_epochs} = {train_loss.numpy()}. Test loss = {test_loss.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter_notebook",
   "language": "python",
   "name": "jupyter_notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
